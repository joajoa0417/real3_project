# Ollama Gemma3:4b Chatbot

Ollamaμ Gemma3:4b λ¨λΈμ„ μ‚¬μ©ν•λ” μ±„ν…λ΄‡ API μ„λ²„μ…λ‹λ‹¤.

## π€ λΉ λ¥Έ μ‹μ‘

### 1. Ollama μ„¤μΉ
λ¨Όμ € Ollamaλ¥Ό μ„¤μΉν•΄μ•Ό ν•©λ‹λ‹¤:
- Windows: https://ollama.ai μ—μ„ λ‹¤μ΄λ΅λ“
- λλ” PowerShellμ—μ„: `winget install Ollama.Ollama`

### 2. Ollama μ„λ²„ μ‹μ‘
```bash
ollama serve
```

### 3. Gemma3:4b λ¨λΈ μ„¤μΉ
```bash
ollama pull gemma3:4b
```

### 4. Python μμ΅΄μ„± μ„¤μΉ
```bash
cd chatbot
pip install -r requirements.txt
```

### 5. μ„λ²„ μ‹¤ν–‰
```bash
python run_server.py
```

## π“‹ API μ—”λ“ν¬μΈνΈ

### κΈ°λ³Έ μ •λ³΄
- **μ„λ²„ μ£Όμ†**: http://localhost:8000
- **API λ¬Έμ„**: http://localhost:8000/docs

### μ—”λ“ν¬μΈνΈ λ©λ΅

#### 1. ν—¬μ¤ μ²΄ν¬
```
GET /health
```
Ollama μ„λ²„ μ—°κ²° μƒνƒλ¥Ό ν™•μΈν•©λ‹λ‹¤.

#### 2. λ¨λΈ λ©λ΅ μ΅°ν
```
GET /models
```
μ‚¬μ© κ°€λ¥ν• Ollama λ¨λΈ λ©λ΅μ„ λ°ν™ν•©λ‹λ‹¤.

#### 3. μ±„ν…
```
POST /chat
```
Gemma3:4b λ¨λΈκ³Ό μ±„ν…ν•©λ‹λ‹¤.

**μ”μ²­ μμ‹:**
```json
{
  "messages": [
    {"role": "user", "content": "μ•λ…•ν•μ„Έμ”!"}
  ],
  "model": "gemma3:4b",
  "stream": false
}
```

#### 4. ν…μ¤νΈ μƒμ„±
```
POST /generate
```
ν”„λ΅¬ν”„νΈλ¥Ό κΈ°λ°μΌλ΅ ν…μ¤νΈλ¥Ό μƒμ„±ν•©λ‹λ‹¤.

## π”§ κ°λ° ν™κ²½ μ„¤μ •

### ν™κ²½ λ³€μ
`.env` νμΌμ„ μƒμ„±ν•μ—¬ μ„¤μ •μ„ μ»¤μ¤ν„°λ§μ΄μ¦ν•  μ μμµλ‹λ‹¤:

```env
OLLAMA_BASE_URL=http://localhost:11434
```

### λ΅μ»¬ κ°λ°
```bash
# κ°λ° λ¨λ“λ΅ μ‹¤ν–‰ (μλ™ λ¦¬λ΅λ“)
python run_server.py

# λλ” μ§μ ‘ uvicorn μ‚¬μ©
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

## π“± ν”„λ΅ νΈμ—”λ“ μ—°κ²°

React Native μ•±μ—μ„ μ΄ APIλ¥Ό μ‚¬μ©ν•λ ¤λ©΄:

```typescript
const chatWithGemma = async (message: string) => {
  try {
    const response = await fetch('http://localhost:8000/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        messages: [
          { role: 'user', content: message }
        ],
        model: 'gemma3:4b'
      })
    });
    
    const data = await response.json();
    return data.response;
  } catch (error) {
    console.error('μ±„ν… μ¤λ¥:', error);
    throw error;
  }
};
```

## π› λ¬Έμ  ν•΄κ²°

### 1. Ollama μ„λ²„ μ—°κ²° μ‹¤ν¨
- Ollamaκ°€ μ„¤μΉλμ–΄ μλ”μ§€ ν™•μΈ: `ollama --version`
- Ollama μ„λ²„κ°€ μ‹¤ν–‰ μ¤‘μΈμ§€ ν™•μΈ: `ollama serve`

### 2. λ¨λΈ λ‹¤μ΄λ΅λ“ μ‹¤ν¨
- μΈν„°λ„· μ—°κ²° ν™•μΈ
- μ¶©λ¶„ν• λ””μ¤ν¬ κ³µκ°„ ν™•λ³΄ (μ•½ 2.5GB ν•„μ”)
- λ°©ν™”λ²½ μ„¤μ • ν™•μΈ

### 3. API μ”μ²­ νƒ€μ„μ•„μ›ƒ
- λ¨λΈ λ΅λ”© μ‹κ°„μ΄ κΈΈ μ μμ (μ²« μ”μ²­ μ‹)
- GPU λ©”λ¨λ¦¬ λ¶€μ΅± μ‹ CPU λ¨λ“λ΅ μ „ν™

## π“ μ„±λ¥ μµμ ν™”

### λ©”λ¨λ¦¬ μ‚¬μ©λ‰
- Gemma3:4bλ” μ•½ 2.5GB RAM μ‚¬μ©
- GPU μ‚¬μ© μ‹ λ” λΉ λ¥Έ μ‘λ‹µ μ†λ„

### μ‘λ‹µ μ†λ„ κ°μ„ 
- μ²« μ”μ²­ ν›„ λ¨λΈμ΄ λ©”λ¨λ¦¬μ— λ΅λ“λμ–΄ λ” λΉ λ¦„
- λ°°μΉ μ”μ²­μΌλ΅ μ²λ¦¬λ‰ ν–¥μƒ κ°€λ¥

## π”’ λ³΄μ• κ³ λ ¤μ‚¬ν•­

- ν”„λ΅λ•μ… ν™κ²½μ—μ„λ” CORS μ„¤μ •μ„ μ ν•ν•μ„Έμ”
- API ν‚¤ μΈμ¦ μ¶”κ°€ κ³ λ ¤
- μ”μ²­ ν¬κΈ° μ ν• μ„¤μ •

## π“ λΌμ΄μ„Όμ¤

μ΄ ν”„λ΅μ νΈλ” MIT λΌμ΄μ„Όμ¤ ν•μ— λ°°ν¬λ©λ‹λ‹¤. 